# 分布式生产环境的搭建—非高可用环境搭建


本篇主要介绍使用四台机器搭建`Hadoop`分布式环境，由于是实验学习环境，所以暂时不对着急搭建分布式的高可用方案，先从最基本的一步一步搭建，从中穿插介绍一些个人的理解以及查阅的资料。






## 一、Hadoop版本选择

|   序号  | 组件名称 | 组件版本 |
|:-------| :------- | :-----  |
| 1      | hadoop  |   2.7.5 |
| 2      |    JDK     |  jdk1.8.0_65  |



## 二、部署构架环境信息说明

本次实验使用到4台服务器，搭建生产环境并非必须4台服务器，三台服务器即可，因为是实验测试环境，为了方便测试性能以及功能的调试，便于学习组件。如下表所示是每一个服务器的所运行的组件信息


|序号| 服务器IP | 功能角色 |
|:---:|:----:|:----:|
| 1 | 192.168.208.60(namenode1)| NameNode、ResourceManager |
| 2 | 192.168.208.61(datanode1)| SecondaryNameNode、NodeManager、DataNode |
| 3 | 192.168.208.62(datanode2)| NodeManager、DataNode |
| 4 | 192.168.208.63(datanode3)| NodeManager、DataNode |


 如上表示，各个功能角色作用描述如下
- `NameNode`  负责存储`HDFS`文件系统的元数据信息，里面记录了文件系统中所有文件的大小以及块信息
- `ResourceManager` 是`Yarn`资源管理器中的一个角色，实现统计与分配`Hadoop`集群上计算资源，主要是`CPU`和`MEM`
- `NodeManager` 实现自己本机的资源管理与监控
- `DataNode`    存储数据副本进程
- `SecondaryNameNode` 实现定时合并`HDFS`文件系统的`fsimage`和`edits`文件，在出现问题时，我们可以将该处的文件覆盖至namenode中，重新拉起namenode，但是以为合并是定时合并的，所以肯定会有一小部分数据丢失的问题

## 三、分布式环境搭建步骤

基于以上的环境介绍，现在开始搭建分布式环境，具体的步骤如下，总的来说具体的步骤可以参考[官方搭建文档](http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/ClusterSetup.html)

### 3.1、安装与部署JDK

该步骤比较简单，再次我们选择`JDK`版本为`1.8`，至于官方对`JDK`版本的要求，可以[查询该文档](https://wiki.apache.org/hadoop/HadoopJavaVersions)，有详细的说明。

```bash
Shell> curl -O http://fdoc.epoint.com.cn:3366/JDK/jdk-8u65-linux-x64.tar.gz
Shell> tar -zxvf jdk-8u65-linux-x64.tar.gz -C /opt/
Shell> ln -s /opt/jdk1.8.0_65 /usr/local/jdk
Shell> vim /etc/profile #编辑配置文件，添加如下内容
#######省略部分输出#########
# JAVA JDK Setting
export JAVA_HOME=/usr/local/jdk
export PATH=$PATH:$JAVA_HOME/bin
Shell> source /etc/profile

```
配置完成后请记住`source`配置文件。该步骤需要在三台机器上都要执行



### 3.2、配置主机间相互信任与主机名称访问

配置主机名，方法非常简单，编辑修改`/etc/hostname`修改为上表中计划配置的主机名称，配置完主机名称修改每台主机的`/etc/hosts`文件加入主机名与`IP`地址的对应关系，内容如下所示
```bash
[root@namenode1 ~]# cat /etc/hosts
......省略已有的默认配置..........
192.168.208.60 namenode1
192.168.208.61 datanode1
192.168.208.62 datanode2
192.168.208.63 datanode3
```

完成上述配置后我们开始配置主机之间的相互信任，配置很简单，原理也比较简单，就是在本机上生成自己的公钥，在将公钥发送至其他机器上，下次在登录其他机器上时，验证登录机器上的公钥和私钥即可证明身份

```bash
[root@namenode1 ~]$ ssh-keygen -t rsa # 请注意执行该命令的机器是在namenode1机器上
[root@namenode1 ~]$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/home/ijarvis/.ssh/id_rsa): #指定私钥生成地址，默认即可
Enter passphrase (empty for no passphrase): #输入秘钥认证密码，实现免密码登录直接回车即可
Enter same passphrase again:
Your identification has been saved in /home/ijarvis/.ssh/id_rsa.
Your public key has been saved in /home/ijarvis/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:P5g1xDuo8sfY5sHpI5tJIv7ylcIujFOmn5ZcINt5aog ijarvis@ijarvis
The key's randomart image is:
+---[RSA 2048]----+
|                 |
|         .       |
|          o      |
|. .      o .     |
| + o    S =      |
|. =.o  + * o     |
|.O.== =+* o      |
|E.X+ Bo+*. .     |
| =+=+ =*o.       |
+----[SHA256]-----+
[root@namenode1 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub root@datanode1 # 将namenode1的公钥发送追加至datanode1主机中
[root@namenode1 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub root@datanode2 
[root@namenode1 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub root@datanode3 # 如上步骤所示，将自己的key配置到其他机器上
```

### 3.3、配置Hadoop集群配置文件

修改与配置`Hadoop`配置文件很简单，在初始状态下集群内的文件配置都是一样的，只要在一台机器上修改好其他的机器使用`scp`配置替换就好了。

首先配置`Hadoop`的环境变量信息，这些变量信息指定了`Hadoop`集群的配置文件位置等信息，我们这里现在`namenode1`机器上配置，然后在同步至其他的`datanode`上即可，方法如下
```bash
Shell> vim /etc/profile
.......省略部分配置......
# Hadoop Install Setting
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
```



